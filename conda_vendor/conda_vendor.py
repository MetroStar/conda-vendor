""" The main idea is to pass an isolated environment (environment.yaml)  to
 conda-lock and get a list of packages, locations, and metadata.  We
 download all the packages specified into a solution into the directory
 structure of a Conda channel.  We grab the repodata for each package from
 the original source and write a condensed repodata.json only having our
 vendored packages.
"""
import hashlib
import json
import struct
import sys

from pathlib import Path
from pprint import pformat
from shlex import split
from shutil import which
from subprocess import check_output
from typing import List, Union

import click
import requests
import yaml

from packaging import version
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
from ruamel.yaml import YAML


from conda_lock import __version__ as conda_lock_version
from conda_lock.conda_solver import (
    DryRunInstall,
    FetchAction,
)
from conda_lock.conda_solver import (
    _reconstruct_fetch_actions as reconstruct_fetch_actions,
)
from conda_lock.conda_solver import solve_specs_for_arch
from conda_lock.invoke_conda import is_micromamba
from conda_lock.src_parser import LockSpecification
from conda_lock.src_parser.environment_yaml import parse_environment_file
from conda_lock.virtual_package import (
    FakeRepoData,
    default_virtual_package_repodata,
    virtual_package_repo_from_specification,
)

from conda_vendor.version import __version__


#  conda-lock:
#  the solution returned by conda-lock is essentially a dictionary with
#  {
#       'actions':
#       {
#            'LINK': [ link_actions, ...],
#            'FETCH': [ fetch_actions, ...]
#       }
#  }
#
#  the fetch_actions are essentially a struct with info in repodata.json
#
#  class FetchAction(TypedDict):
#      """
#      FETCH actions include all the entries from the corresponding package's
#      repodata.json
#      """
#
#      channel: str
#      constrains: Optional[List[str]]
#      depends: Optional[List[str]]
#      fn: str
#      md5: str
#      sha256: Optional[str]
#      name: str
#      subdir: str
#      timestamp: int
#      url: str
#      version: str


def _blue(msg: str, bold: bool = True):
    click.echo(click.style(msg, fg="blue", bg="black", bold=bold))


def _cyan(msg: str, bold: bool = True):
    click.echo(click.style(msg, fg="cyan", bg="black", bold=bold))


def _green(msg: str, bold: bool = True):
    click.echo(click.style(msg, fg="green", bg="black", bold=bold))


def _red(msg: str, bold: bool = True):
    click.echo(click.style(msg, fg="red", bg="black", bold=bold))


def _yellow(msg: str, bold: bool = True):
    click.echo(click.style(msg, fg="yellow", bg="black", bold=bold))


def _generate_lock_spec(
    environment_file: Path, platform: str
) -> LockSpecification:
    # the function parameters changed in conda-lock 1.3.0
    if version.parse(conda_lock_version) < version.parse("1.3.0"):
        # pylint: disable=no-value-for-parameter
        return parse_environment_file(environment_file)
    else:
        return parse_environment_file(environment_file, [platform])


def _get_environment_name(environment_file: Path) -> str:
    """find the name of the environment from the environment.yaml"""

    with open(environment_file, "r") as f:
        _yaml = yaml.safe_load(f)
        return _yaml["name"]


def _get_virtual_packages(
    platform: str, virtual_package_spec: Union[Path, str] = None
) -> FakeRepoData:
    """return a fake repository object  containing the virtual packages
    specified or the conda-lock defaults if virtual_package_spec is None

    If we are vendoring for the same platform we are on, do not
    specify virtual packages.

    Parameters
    ----------
    virtual_package_spec: pathlib.Path or str
        path to location of yaml specifying virtual packages

    platform: str
        platform to solve for virtual packages for
    """
    if virtual_package_spec is not None:
        if isinstance(virtual_package_spec, str):
            virtual_package_spec = Path(virtual_package_spec)
        return virtual_package_repo_from_specification(virtual_package_spec)

    if platform != _get_conda_platform():
        return default_virtual_package_repodata()

    return None


def _get_query_list(lock_spec: LockSpecification) -> List[str]:
    """Go through the LockSpecification object and grab all the packages
    with their versions into a list.

    Parameters
    ----------
    lock_spec: conda_lock.src_parser.LockSpecification
        a lock spec generated by conda_lock from the initial enviroment.yaml

    Returns
    -------
    list
       a formatted list of Python packages with their dependency requirements

    """
    specs = []
    for dep in lock_spec.dependencies:
        if dep.version == "":
            specs.append(f"{dep.name}")
        else:
            if dep.version[0].isnumeric():
                specs.append(f"{dep.name}=={dep.version}")
            else:
                specs.append(f"{dep.name}{dep.version}")
    return specs


def _remove_channel(
    solution: DryRunInstall, channel: str, solver: str = "conda"
):
    """Filter a conda-lock solution and remove any packages from the specified
    channel.

    Parameters
    ----------
    solution: conda_lock.conda_solver.DryRunInstall
        valid solution from conda-lock

    channel: str
        the channel to remove.

    solver: str
        which solver to use.  Micromamba has a different form for "LINK" actions
        than conda or mamba
    """
    fetch = []
    link = []

    for entry in solution["actions"]["FETCH"]:
        if entry["channel"].startswith(channel):
            continue
        fetch.append(entry)

    if not is_micromamba(solver):
        for entry in solution["actions"]["LINK"]:
            if entry["base_url"] == channel:
                continue
            link.append(entry)
    else:
        for entry in solution["actions"]["LINK"]:
            if entry["channel"].startswith(channel):
                continue
            link.append(entry)

    solution["actions"]["FETCH"] = fetch
    solution["actions"]["LINK"] = link
    return solution


def _print_solve_configuration(
    solver: str,
    platform: str,
    spec: List[str],
    virt_pkgs: FakeRepoData = None,
):
    _cyan(f"Using Solver: {solver}", bold=False)
    _cyan(f"Solving for Platform: {platform}", bold=False)

    _print_spec = pformat(spec, width=78, compact=True)
    if len(_print_spec) < 70:
        _cyan(f"Spec: {_print_spec}", bold=False)
    else:
        _cyan("Spec:", bold=False)
        _cyan(f"{_print_spec}", bold=False)

    if virt_pkgs:
        virt_pkg_list = virt_pkgs.all_repodata[platform]["packages"].values()
    else:
        virt_pkg_list = _get_system_virtual_packages(solver)

    _print_virt_pkgs = pformat(
        [f"{pkg['name']}: {pkg['version']}" for pkg in virt_pkg_list],
        width=78,
        compact=True,
    )

    if len(_print_virt_pkgs) < 60:
        _cyan(f"Virtual Packages: {_print_virt_pkgs}", bold=False)
    else:
        _cyan("Virtual Packages:", bold=False)
        _cyan(f"{_print_virt_pkgs}", bold=False)


def solve_environment(
    environment_file: Path,
    solver: str,
    platform: str,
    virtual_package_spec: Union[Path, str] = None,
) -> List[FetchAction]:
    """Solve the environment specified in the conda environment_file,
    and return a list of all the required packages with enough metadata
    to generate a repo_data.json.

    Parameters
    ----------
    environment_file: pathlib.Path
        path to the environment.yaml to solve

    solver: str
        which conda is used to solve: conda, mamba, micromamba, etc.

    platform: str
        platform to vendor for: eg. linux-32, win-64, osx-64, etc.

    virtual_package_spec: pathlib.Path or str
        location of a conda-lock virtual package specification yaml.  See
        the documentation for conda-lock for the correct format.  If
        this is None, use the default virtual packages that conda-lock
        provides for {platform}

    Returns
    -------
    list [ conda_lock.conda_solver.FetchAction ]

    """
    assert isinstance(environment_file, Path)

    # generate conda-lock's LockSpecification, this will parse the environment
    # file for us and give us more easily handled requirements.
    lock_spec = _generate_lock_spec(environment_file, platform)
    spec = _get_query_list(lock_spec)

    virt_pkgs = _get_virtual_packages(platform, virtual_package_spec)
    _print_solve_configuration(solver, platform, spec, virt_pkgs)
    channels = lock_spec.channels
    if virt_pkgs:
        channels.append(virt_pkgs.channel)

    solution = solve_specs_for_arch(solver, channels, spec, platform)

    if virt_pkgs:
        solution = _remove_channel(
            solution, virt_pkgs.channel_url_posix, solver
        )

    if not solution["success"]:
        _red(f"Failed to Solve for {spec}")
        _red(f"Using {solver} for {platform}")
        sys.exit(1)
    _green("Successfull Solve")

    # unfortunately Conda sometimes doesn't fill out the FETCH actions
    # completely so conda-lock will generate the appropriate FETCH action from
    # the LINK action and the repodata_record.json
    patched_solution = reconstruct_fetch_actions(solver, platform, solution)
    return patched_solution["actions"]["FETCH"]


# pylint: disable=line-too-long
# see https://stackoverflow.com/questions/21371809/cleanly-setting-max-retries-on-python-requests-get-or-post-method
def _improved_download(url: str):
    """Wrapper arround request.get() to allow for retries

    Parameters
    ----------
    url: str
        url to fetch

    Returns
    -------
    request.Response
        response object containing the fetched file
    """
    session = requests.Session()
    retry = Retry(connect=5, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session.get(url)


def _create_repodata_for_subdir(
    subdir: str, package_list: List[FetchAction]
) -> dict:
    """
    Create an in memory repodata object for the subdirectory {subdir} from the
    list of packages supplied.  This goes out to the actual channel the
    solution specifies and gets a copy of the channels repodata.json and uses
    that to create the local repodata dictionary.

    Parameters
    ----------
    subdir: str
        subdirectory to create repodata.json for, e.g. linux-64, noarch, ...

    package_list: List[FetchAction]
        list of packages to vendor.  **These packages should all satisfy the
        precondition that package["subdir"] == {subdir}**

    Returns
    -------
    dictionary object that is the structured repodata

    """
    repo_data = {
        "info": {"subdir": subdir},
        "packages": {},
        "packages.conda": {},
    }

    channels = list(set((pkg["channel"] for pkg in package_list)))
    for chan in channels:
        channel_packages = [
            pkg for pkg in package_list if pkg["channel"] == chan
        ]

        url = f"{chan}/repodata.json"
        _yellow(f"Downloading {url}")

        live_repodata_json = _improved_download(url).json()
        _live_pkgs = live_repodata_json.get("packages", {})
        _live_pkgs_conda = live_repodata_json.get("packages.conda", {})

        label = url if len(url) < 30 else f"...{url[-30:]}"
        with click.progressbar(channel_packages, label=label) as packages:
            for pkg in packages:
                _live_repodata = _live_pkgs.get(pkg["fn"])
                if _live_repodata:
                    assert repo_data["packages"].get(pkg["fn"]) is None
                    repo_data["packages"][pkg["fn"]] = _live_repodata
                    continue

                _live_repodata = _live_pkgs_conda.get(pkg["fn"])
                if _live_repodata:
                    assert repo_data["packages.conda"].get(pkg["fn"]) is None
                    repo_data["packages.conda"][pkg["fn"]] = _live_repodata
                    continue

                _red(f"unable to find package {pkg['fn']} at {url}")
                _red(pkg)
                sys.exit(1)

    return repo_data


def create_repodata_json(
    package_list: List[FetchAction], vendored_root: Path, platform: str
):
    """Go through the package_list, i.e. the solution provided by conda_lock,
    and generate a new repodata.json at vendored_root/{subdir}, where
    subdir is either noarch or the platform (as specified in the metadata
    in package_list).

    Parameters
    ----------
    package_list: list [ conda_lock.conda_solver.FetchAction ]
        list of packages (and their metadata) provided by conda-lock

    vendored_root: pathlib.Path
        location of the root of the new conda channel

    platform: str
        platform to vendor
    """
    assert isinstance(vendored_root, Path)

    subdirs = [platform, "noarch"]

    _blue(70 * "=")
    for pkg in package_list:
        subdirs.append(pkg["subdir"])

        _yellow(f"Channel: {pkg['channel']}", bold=False)
        _yellow(f"Package: {pkg['fn']}", bold=False)
        _yellow(f"URL: {pkg['url']}", bold=False)
        _yellow(f"SHA256: {pkg['sha256']}", bold=False)
        _yellow(f"Subdirectory: {pkg['subdir']}", bold=False)
        _yellow(f"Timestamp: {pkg['timestamp']}", bold=False)
        click.echo()

    _blue(70 * "=")

    subdirs = list(set(subdirs))
    for subdir in subdirs:
        repo_data = _create_repodata_for_subdir(
            subdir,
            [pkg for pkg in package_list if pkg["subdir"] == subdir],
        )

        # write to destination
        dest_file = vendored_root / subdir / "repodata.json"
        with dest_file.open("w") as f:
            json.dump(repo_data, f)

    _blue(70 * "=")


# TODO: download and checksum in chunks
# https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests
def download_packages(package_list: List[FetchAction], vendored_root: Path):
    """For each Conda package specified in package_list.  Fetch the binary
    from the url (in the metadata).  Calculate the checksum and verify
    it with the provided checksum.

    Parameters
    ----------
    package_list: list [ conda_lock.conda_solver.FetchAction ]
        list of packages (and their metadata) provided by conda-lock

    vendored_root: pathlib.Path
        location of the root of the new conda channel
    """
    assert isinstance(vendored_root, Path)
    _green("Downloading and Verifying SHA256 Checksums for Solved Packages")

    with click.progressbar(
        package_list, label="Downloading Progress"
    ) as pkgs:
        for pkg in pkgs:
            dest_dir = vendored_root / pkg["subdir"]
            assert dest_dir.exists() and dest_dir.is_dir()

            response = _improved_download(pkg["url"])
            if response.status_code >= 400:
                _red(f"Download Failed for {pkg['url']}")
                _red(f"server responded: {response.status_code}")
                sys.exit(1)

            file_data = response.content

            # verify checksum
            sha256 = hashlib.sha256(file_data).hexdigest()
            if sha256 != pkg["sha256"]:
                _red(f"SHA256 Checksum Validation Failed for {pkg['fn']}")
                sys.exit(1)

            with open(dest_dir / pkg["fn"], "wb") as f:
                f.write(file_data)


def yaml_dump_ironbank_manifest(package_list: List[FetchAction]):
    """This generates formatted text to insert into the DoD IronBank's
    hardening_manifest.yaml "resources" block.

    Parameters
    ----------
    package_list: list [ conda_lock.conda_solver.FetchAction ]
        list of packages (and their metadata) provided by conda-lock
    """

    _cyan("Generating Iron Bank resources clause")

    # IronBank formatted 'resources' block
    resources = {
        "resources": [],
    }

    for pkg in package_list:
        validation = {"type": "sha256", "value": pkg["sha256"]}
        resource = {
            "url": pkg["url"],
            "filename": pkg["fn"],
            "validation": validation,
        }

        resources["resources"].append(resource)

    yaml_ = YAML()
    with open("ib_manifest.yaml", "w") as f:
        yaml_.dump(resources, f)
    _green("Iron Bank resources list written to ib_manifest.yaml")


###########################################################################
#                                                                         #
#                                main                                     #
#                                                                         #
###########################################################################


@click.group()
@click.version_option(__version__)
def main() -> None:
    """Display help and usage for subcommands, use: conda-vendor [COMMAND] --help"""
    pass  # pylint: disable=unnecessary-pass


# see https://github.com/conda/conda/blob/248741a843e8ce9283fa94e6e4ec9c2fafeb76fd/conda/base/context.py#L51
def _get_conda_platform(platform=None) -> str:
    """Get the platform string (the string Conda needs) but allow the
    caller to override.

    Parameters
    ----------
    platform: str
        platform in Python's format to be converted to Conda's format if
        it is provided, just use it. Otherwise convert the string to something
        that Conda wants
    """

    if platform is not None:
        return platform

    platform = sys.platform
    bits = struct.calcsize("P") * 8

    _platform_map = {
        "linux2": "linux",
        "linux": "linux",
        "darwin": "osx",
        "win32": "win",
        "zos": "zos",
    }

    return f"{_platform_map[platform]}-{bits}"


def _get_system_virtual_packages(solver: str) -> List[dict]:
    """Get a list of the systems virtual packages

    Parameters
    ----------
    solver: str
        solver to use.  conda, mamba, etc.

    Returns
    -------
    list[dict]
        a list of virtual packages as a dictionary having keys name, version,
        and build_string
    """

    conda_info = check_output(split(f"{solver} info --json"), text=True)
    _json = json.loads(conda_info)
    virtual_packages = []

    if not is_micromamba(solver):
        for pkg in _json.get("virtual_pkgs", []):
            virtual_packages.append(
                    {"name": pkg[0], "version": pkg[1], "build_string": pkg[2]}
                    )
    else:
        for pkg in _json.get("virtual packages", []):
            pkg = pkg.split("=")
            virtual_packages.append(
                    {"name": pkg[0], "version": pkg[1], "build_string": pkg[2]}
                    )
    return virtual_packages


def _validate_solver(solver: str):
    """make sure we have an actual binary to solve with

    Parameters
    ----------
    solver: str
        solver to use e.g. conda, mamba, micromamba
    """
    if which(solver) is None:
        _red(f"Unable to find {solver} on PATH.")
        sys.exit(1)


###########################################################################
#                                                                         #
#                    conda-vendor vendor                                  #
#                                                                         #
###########################################################################


@click.command(
    "vendor",
    help="Vendor dependencies into a local channel, given an environment file",
)
@click.option(
    "-f", "--file", default=None, help="Path to solvable environment.yaml"
)
@click.option(
    "-s",
    "--solver",
    default="conda",
    help="Solver to use. Examples: conda, mamba, micromamba",
)
@click.option(
    "-p",
    "--platform",
    default=_get_conda_platform(),
    help="Platform to solve for.",
)
@click.option(
    "--virtual-package-spec",
    default=None,
    help="specify virtual packages injected into conda-lock solution",
)
@click.option(
    "--dry-run",
    default=False,
    is_flag=True,
    help="Dry Run. Doesn't Download Packages - Returns Formatted JSON of FETCH Action Packages",
)
@click.option(
    "--ironbank-gen",
    default=False,
    is_flag=True,
    help="Save IronBank Resources 'ib_manifest.yaml' in current directory",
)
# pylint: disable=too-many-arguments
def vendor(
    file: str,
    solver: str,
    platform: str,
    virtual_package_spec: str,
    dry_run: bool,
    ironbank_gen: bool,
):
    """Main entry point to vendor a file.  This will (in the general case)
    use conda-lock to solve the environment specified in an environment.yaml
    passed in through file parameter. After a valid solution, it will
    download the corresponding Conda packages to a channel in
    current_dir/environment_name.  It creates a valid repodata.json for
    each of the Conda required subdirectories.

    Parameters
    ----------
    file: str
        location of environment.yaml to solve

    solver: str
        specified Conda solver, e.g. conda, micromamba, mamba

    platform: str
        platform to vendor, e.g. linux-32, linux-64, osx-64, win-32

    virtual_package_spec: str
        location of virtual-packages.yml to be used by conda-lock.  The format
        of the virtual-packages.yml is specified in the conda-lock
        documentation.
        Note: if a file named virutal-packages.yml exist in the directory
        where conda-lock is run it will use that file.
        see (https://github.com/conda-incubator/conda-lock).

    dry_run: bool
        if specified just try to solve the environment and dump the solution
        set to stdout.

    ironbank_gen: bool
        if specified create an Iron Bank resources clause (in a yaml)
        "ib_manifest.yaml" in the current directory
    """
    _green(f"Vendoring Local Channel for file: {file}", bold=False)

    environment_file = Path(file)
    environment_name = _get_environment_name(environment_file)
    _validate_solver(solver)

    vendored_root = Path.cwd() / environment_name
    if vendored_root.exists():
        _red(f"vendored channel destination {vendored_root} already exists")
        sys.exit(1)

    if dry_run:
        _yellow("Dry Run - Will Not Download Files")
    else:
        Path.mkdir(vendored_root)
        Path.mkdir(vendored_root / platform)
        Path.mkdir(vendored_root / "noarch")

    package_list = solve_environment(
        environment_file, solver, platform, virtual_package_spec
    )

    if dry_run:
        _green("Dry Run Complete!")
        click.echo(json.dumps(package_list, indent=4))
        sys.exit(0)

    create_repodata_json(package_list, vendored_root, platform)
    download_packages(package_list, vendored_root)

    _green("SHA256 Checksum Validation and Packages Downloaded")
    _green("Vendoring Complete!")
    _green(f"Vendored Channel: {vendored_root}")

    if ironbank_gen:
        yaml_dump_ironbank_manifest(package_list)


###########################################################################
#                                                                         #
#              conda-vendor ironbank_gen                                  #
#                                                                         #
###########################################################################


@click.command(
    "ironbank-gen",
    help="Generate Formatted Text to use in IronBank's Hardening Manifest",
)
@click.option("-f", "--file", default=None, help="Path to environment.yaml")
@click.option(
    "-s",
    "--solver",
    default="conda",
    help="Solver to use. conda, mamba, micromamba",
)
@click.option(
    "--platform",
    "-p",
    default=_get_conda_platform(),
    help="Platform to solve for.",
)
@click.option(
    "--virtual-package-spec",
    default=None,
    help="specify virtual packages injected into conda-lock solution",
)
def ironbank_gen(
    file: str, solver: str, platform: str, virtual_package_spec: str
):
    """Create an Iron Bank resources clause (in a yaml) "ib_manifest.yaml" in
    the current directory

    Parameters
    ----------
    file: str
        location of environment.yaml to solve

    solver: str
        specified Conda solver, e.g. conda, micromamba, mamba

    platform: str
        platform to vendor, e.g. linux-32, linux-64, osx-64, win-32

    virtual_package_spec: str
        location of virtual-packages.yml to be used by conda-lock.  The format
        of the virtual-packages.yml is specified in the conda-lock
        documentation.
        Note: if a file named virutal-packages.yml exist in the directory
        where conda-lock is run it will use that file.
        see (https://github.com/conda-incubator/conda-lock).
    """
    _validate_solver(solver)
    package_list = solve_environment(
        Path(file), solver, platform, virtual_package_spec
    )
    yaml_dump_ironbank_manifest(package_list)


###########################################################################
#                                                                         #
#              conda-vendor virtual-packages                              #
#                                                                         #
###########################################################################
@click.command("virtual-packages", help="dump host virtual packages")
@click.option(
    "--solver",
    default="conda",
    help="Solver to use. conda, mamba, micromamba",
)
@click.option(
    "-o",
    "--output",
    default=None,
    help="name of file to write.  Default is stdout.",
)
def virtual_packages(solver, output):
    _validate_solver(solver)
    virtual_packages = _get_system_virtual_packages(solver)

    package_list = {}
    for pkg in virtual_packages:
        package_list[pkg["name"]] = pkg["version"]

    virtual_packages_dict = {
        "subdirs": {f"{_get_conda_platform()}": {"packages": package_list}}
    }

    if output:
        with open(output, "w") as f:
            yaml.dump(virtual_packages_dict, f, indent=4)
    else:
        yaml.dump(virtual_packages_dict, sys.stdout, indent=4)


main.add_command(vendor)
main.add_command(ironbank_gen)
main.add_command(virtual_packages)

if __name__ == "main":
    main()
